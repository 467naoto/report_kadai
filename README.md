# 大規模言語モデル　課題

1. 自分が扱ってみたい単純な自然言語処理タスクを１つ選定し、選んだタスクについて、使用可能な事前学習済みモデルを１つ選べ、モデル名・入力形式・用途・モデル規模（パラメータ数）・事前学習データ量・訓練過程を表にまとめよ

### ニュースの見出しの分類

| モデル名 | 入力形式 | 用途 | モデル規模 | 事前学習データ量 | 訓練過程 |
|-----------|------------|--------|--------------|------------------|------------|
| cl-tohoku/bert-base-japanese-v3 | 日本語テキストをトークナイザーでサブワードに分割して入力、最大長512トークン | 文章分類、固有表現抽出 | 約110Mパラメータ（層数:12、隠れ次元:768、Attentionヘッド数:12） | 約20GBの日本語テキスト | MLM、NSP、AdamW |

<br>
<br>
    
2. プロンプト制御・文脈内学習・CoTのうち１つを、１で選んだタスクに当てはめ、「どう使えそうか」「どう改善が期待できるか」について仮説を立て説明せよ

### プロンプト制御を当てはめるとする

### どう使えそうか
ニュースの見出しをカテゴリに分類する際
BERTに対して、プロンプトを入力文に付加することで文脈的理解を促すことができると考える

### どう改善が期待できるか
プロンプトを入力文に付与することで、曖昧なニュースの見出しがあった場合に対する文脈理解の向上が見込めると考える


3.アライメント/無害性/指示チューニングといった観点から、１で選んだタスクにおける「リスク（誤答、バイアス、無害性違反など）」を１つ挙げ、それに対してどのような対策が考えられるかを説明せよ

ニュースの見出し分類では、社会的・政治的バイアスが生じるリスクが考えられる。例を挙げると、特定の政治家や企業名を含む見出しが自動的に「政治」「経済」といったカテゴリに分類されてしまう可能性があ理、モデルが事前学習データ中の偏見を反映してしまうことがあると考える。こういったアライメント上の問題への対策としては、出力内容の分析（誤分類傾向の分析）や、プロンプト設計の工夫（中立的な文を使用して、評価基準を明確化するなど）が挙げられる。(218字）

4.１で選んだタスクに対して、軽量ファインチューニングを行え。例えば、少数データ（100~500件）を準備して、モデルをファインチューニングし、その前後での性能を比較せよ。さらに「どこでうまくいったか/うまくいかなかったか」を整理し、エラー分析的な視点から「モデルのショートカット」「誤分類の傾向」などを簡潔にまとめよ

### ファインチューニング前後の結果
| 比較項目 | ファインチューニング前 | ファインチューニング後 |
| ------- | ---------------- | ---------------- |
| Accuracy| 0.42 | 0.83 |
| Loss | 1.65 | 0.42 |

### うまくいった点
政治・経済・スポーツなどが語彙が特徴的なカテゴリでは高精度に分類することができた。特に「政府」「株式」「試合」といったキーワドが含まれる見出しでは安定した結果を得ることができた

### うまくいかなかった点
「科学・技術」と「経済」などのテクノロジー関連ニュースが曖昧な領域においては混同が生じやすかった。例えば「AIによる自動運転企業の株価の上昇」など複数カテゴリに関する記事で誤分類が発生
※他にも「エンタメ」と「スポーツ」、「科学・技術」と「エンタメ」なども混同が生じる場合があった

### 誤分類の傾向
- 抽象的・比喩的な見出しで分類が不安定
- 固有名詞が登場しても、それがどの分野に関係するのか知識が不足


