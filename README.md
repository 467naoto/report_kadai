# 大規模言語モデル　課題

## 1. 自分が扱ってみたい単純な自然言語処理タスクを１つ選定し、選んだタスクについて、使用可能な事前学習済みモデルを１つ選べ、モデル名・入力形式・用途・モデル規模（パラメータ数）・事前学習データ量・訓練過程を表にまとめよ

### ニュースの見出しの分類

| モデル名 | 入力形式 | 用途 | モデル規模 | 事前学習データ量 | 訓練過程 |
|-----------|------------|--------|--------------|------------------|------------|
| cl-tohoku/bert-base-japanese-v3 | 日本語テキストをトークナイザーでサブワードに分割して入力、最大長512トークン | 文章分類、固有表現抽出 | 約110Mパラメータ（層数:12、隠れ次元:768、Attentionヘッド数:12） | 約20GBの日本語テキスト | MLM、NSP、AdamW |

<br>
<br>
    
## 2. プロンプト制御・文脈内学習・CoTのうち１つを、１で選んだタスクに当てはめ、「どう使えそうか」「どう改善が期待できるか」について仮説を立て説明せよ

#### プロンプト制御を当てはめるとする

### どう使えそうか
ニュースの見出しをカテゴリに分類する際
BERTに対して、プロンプトを入力文に付加することで文脈的理解を促すことができると考える

### どう改善が期待できるか
プロンプトを入力文に付与することで、曖昧なニュースの見出しがあった場合に対する文脈理解の向上が見込めると考える


## 3.アライメント/無害性/指示チューニングといった観点から、１で選んだタスクにおける「リスク（誤答、バイアス、無害性違反など）」を１つ挙げ、それに対してどのような対策が考えられるかを説明せよ

ニュースの見出し分類では、社会的・政治的バイアスが生じるリスクが考えられる。例を挙げると、特定の政治家や企業名を含む見出しが自動的に「政治」「経済」といったカテゴリに分類されてしまう可能性があ理、モデルが事前学習データ中の偏見を反映してしまうことがあると考える。こういったアライメント上の問題への対策としては、出力内容の分析（誤分類傾向の分析）や、プロンプト設計の工夫（中立的な文を使用して、評価基準を明確化するなど）が挙げられる。(218字）

## 4.１で選んだタスクに対して、軽量ファインチューニングを行え。例えば、少数データ（100~500件）を準備して、モデルをファインチューニングし、その前後での性能を比較せよ。さらに「どこでうまくいったか/うまくいかなかったか」を整理し、エラー分析的な視点から「モデルのショートカット」「誤分類の傾向」などを簡潔にまとめよ

### ファインチューニング前後の結果
| 比較項目 | ファインチューニング前 | ファインチューニング後 |
| ------- | ---------------- | ---------------- |
| Accuracy| 0.42 | 0.83 |
| Loss | 1.65 | 0.42 |

### うまくいった点
政治・経済・スポーツなどが語彙が特徴的なカテゴリでは高精度に分類することができた。特に「政府」「株式」「試合」といったキーワドが含まれる見出しでは安定した結果を得ることができた

### うまくいかなかった点
「科学・技術」と「経済」などのテクノロジー関連ニュースが曖昧な領域においては混同が生じやすかった。例えば「AIによる自動運転企業の株価の上昇」など複数カテゴリに関する記事で誤分類が発生
※他にも「エンタメ」と「スポーツ」、「科学・技術」と「エンタメ」なども混同が生じる場合があった

### 誤分類の傾向
- 抽象的・比喩的な見出しで分類が不安定
- 固有名詞が登場しても、それがどの分野に関係するのか知識が不足

## 5.軽量化・効率化（例：バッチサイズ、学習率、勾配累積/LoRAなど）について、今後１で選んだタスクに適用することで改善が期待される工夫を1〜２案挙げ、理由とともに説明せよ
### 1.LoRAの導入
※LoRA：LoRAではモデル全体ではなく一部の重みだけを低ランク行列で更新することで、学習パラメータを大幅に削減する手法
#### 理由
少量データの場合、全パラメータ更新だと過学習しやすいが、LoRAなら汎化性能を維持しつつタスク適応が可能なため
#### 期待される改善点
- 全パラメータ更新よりも過学習しづらく、少量データに相性がいい
- 学習に必要なVRAM/メモリ消費が減り、Colab環境でも高速に学習可能である

### 2.勾配累積+小バッチサイズ
GPUメモリに余裕がない状態でも複数バッチを累積してから1回の更新を行い、実質的にバッチサイズを大きくする
#### 理由
ニュースの見出し分類では、文鳥が短いこともあり、バッチサイズを増やしてもメモリに収まりやすいため
#### 期待される改善点
- 安定した勾配更新が可能になり、精度のブレが減る
- 少量データでも安定して収束しやすい

### まとめ
| 手法 | 期待される改善 | 改善によって良くなる点 |
| --- | ------------ | ---------------- |
| LoRA | 高速、省メモリ、過学習抑制、精度向上 | 少量データのファインチューニング（軽量ファインチューニング） |
| 勾配累積 | 安定した学習、精度向上、メモリ節約 | 小規模環境での精度改善 |


