# 大規模言語モデル　課題

1. 自分が扱ってみたい単純な自然言語処理タスクを１つ選定し、選んだタスクについて、使用可能な事前学習済みモデルを１つ選べ、モデル名・入力形式・用途・モデル規模（パラメータ数）・事前学習データ量・訓練過程を表にまとめよ

### ニュースの見出しの分類

| モデル名 | 入力形式 | 用途 | モデル規模 | 事前学習データ量 | 訓練過程 |
|-----------|------------|--------|--------------|------------------|------------|
| cl-tohoku/bert-base-japanese-v3 | 日本語テキストをトークナイザーでサブワードに分割して入力、最大長512トークン | 文章分類、固有表現抽出 | 約110Mパラメータ（層数:12、隠れ次元:768、Attentionヘッド数:12） | 約20GBの日本語テキスト | MLM、NSP、AdamW |

<br>
<br>
    
2. プロンプト制御・文脈内学習・CoTのうち１つを、１で選んだタスクに当てはめ、「どう使えそうか」「どう改善が期待できるか」について仮説を立て説明せよ

## プロンプト制御を当てはめるとする

### どう使えそうか
ニュースの見出しをカテゴリに分類する際
BERTに対して、プロンプトを入力文に付加することで文脈的理解を促すことができると考える

### どう改善が期待できるか
プロンプトを入力文に付与することで、曖昧なニュースの見出しがあった場合に対する文脈理解の向上が見込めると考える

<br>
3.アライメント/無害性/指示チューニングといった観点から、１で選んだタスクにおける「リスク（誤答、バイアス、無害性違反など）」を１つ挙げ、それに対してどのような対策が考えられるかを説明せよ


